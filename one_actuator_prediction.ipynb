{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# from models import OneActuatorModel\n",
    "# from data import OneActuatorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_F1TENTH_GYM = Path('../f1tenth_gym')\n",
    "BATCH_SIZE = 256\n",
    "FULL_STATE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_race = pd.read_pickle('./data/together/2021-10-07_01_29_53.472821.pkl')['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_race.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneActuatorDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, directory: str, prob_flip: float = 0.5, full_state: bool = False):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            directory - The directory with .pkl files that are going to be unpacked\n",
    "            prob_flip - Probability of doing a vertical flip of the data\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.directory = Path(directory)\n",
    "        self.prob_flip = prob_flip\n",
    "        self.full_state = full_state\n",
    "            \n",
    "        self.size = 0\n",
    "        self.state_colnames = ['position', 'v_x', 'v_y', 'yaw', 'omega']\n",
    "        self.actuator_colnames = ['speed_actuator', 'delta']\n",
    "        self.num_state_coords = len(self.state_colnames)\n",
    "        \n",
    "        self.fetch_data()\n",
    "\n",
    "    def fetch_data(self):\n",
    "        self.data = []\n",
    "        self.cumul_sizes = []\n",
    "        for filename in self.directory.glob('*.pkl'):            \n",
    "            one_race = pd.read_pickle(filename)\n",
    "            self.size += len(one_race) - 1\n",
    "            self.cumul_sizes.append(self.size)\n",
    "            one_race['v_x'] = one_race['velocity'].apply(lambda x: x[0])\n",
    "            one_race['v_y'] = one_race['velocity'].apply(lambda x: x[1])\n",
    "            one_race = one_race[self.state_colnames + self.actuator_colnames].values\n",
    "            self.data.append(one_race)\n",
    "            \n",
    "    def __len__(self) -> int:\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[Dict, Dict]:\n",
    "        which_race = 0\n",
    "        idx_shift = 0\n",
    "        for cum_size in self.cumul_sizes:\n",
    "            if idx >= cum_size:\n",
    "                which_race += 1\n",
    "                idx_shift = cum_size\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        one_race = self.data[which_race]\n",
    "        idx -= idx_shift\n",
    "\n",
    "        ith_row = one_race[idx, :]\n",
    "        i_plus_1th_row = one_race[idx + 1, :]\n",
    "        position_0, v_x0, v_y0, yaw_0, omega_0 = ith_row[:self.num_state_coords]\n",
    "        speed_actuator, delta = ith_row[self.num_state_coords:]\n",
    "        position_1, v_x1, v_y1, yaw_1, omega_1 = i_plus_1th_row[:self.num_state_coords]\n",
    "\n",
    "        position_diff = np.linalg.norm(position_0 - position_1)\n",
    "        yaw_diff = yaw_0 - yaw_1\n",
    "        if yaw_diff > np.pi:\n",
    "            yaw_diff -= (2 * np.pi)\n",
    "        elif yaw_diff < -np.pi:\n",
    "            yaw_diff += (2 * np.pi)\n",
    "                \n",
    "        if np.random.uniform() < self.prob_flip:\n",
    "            yaw_diff = -yaw_diff\n",
    "            delta = -delta\n",
    "            if self.full_state:\n",
    "                v_y0 *= -v_y0\n",
    "                omega_0 = -omega_0\n",
    "                omega_1 = -omega_1\n",
    "        \n",
    "        state_transition_features = np.r_[position_diff, yaw_diff]\n",
    "        if self.full_state:\n",
    "            state_0 = np.r_[v_x0, v_y0, omega_0]\n",
    "            state_1 = np.r_[v_x1, v_y1, omega_1]\n",
    "            state_transition_features = np.r_[state_transition_features, state_0, state_1]\n",
    "            \n",
    "        return  (\n",
    "            {'state_transition_features': state_transition_features},\n",
    "            {'speed_and_delta': np.r_[speed_actuator, delta]}\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = OneActuatorDataset(directory='./data/train', prob_flip=0.5, full_state=FULL_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(train_dataset, BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, targets = train_dataset[100]\n",
    "features_scalers = {key: StandardScaler() for key in features.keys()}\n",
    "targets_scalers = {key: StandardScaler() for key in targets.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features_batch, targets_batch in train_loader:\n",
    "\n",
    "    for feature_name in features.keys():\n",
    "        features_scalers[feature_name].partial_fit(features_batch[feature_name])\n",
    "\n",
    "    for target_name in targets.keys():\n",
    "        targets_scalers[target_name].partial_fit(targets_batch[target_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneActuatorModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size: int, output_size: int, num_layers: int = 3, num_neurons: int = 30):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = [\n",
    "            nn.Linear(input_size, num_neurons),\n",
    "            nn.SiLU(inplace=True),\n",
    "        ]\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(num_neurons, num_neurons))\n",
    "            layers.append(nn.SiLU(inplace=True))\n",
    "\n",
    "        layers.append(nn.Linear(num_neurons, output_size))\n",
    "\n",
    "        self.module = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, state_transition_features):\n",
    "        return {'speed_and_delta': self.module(state_transition_features)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = sum(len(feat) for _, feat in features.items())\n",
    "output_size = sum(len(target) for _, target in targets.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_actuator_model = OneActuatorModel(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "one_actuator_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(train_dataset, BATCH_SIZE, shuffle=True, num_workers=1)\n",
    "\n",
    "valid_dataset = OneActuatorDataset(directory='./data/valid', prob_flip=0.0, full_state=FULL_STATE)\n",
    "valid_loader = data.DataLoader(valid_dataset, BATCH_SIZE, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(one_actuator_model.parameters(), lr=1e-3)\n",
    "train_mses_for_plot = []\n",
    "valid_mses_for_plot = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    ############\n",
    "    # Training #\n",
    "    ############\n",
    "    train_total_mse = 0\n",
    "    one_actuator_model.train()\n",
    "    for features_batch, targets_batch in train_loader:\n",
    "        features_batch = {\n",
    "            feature_name: torch.from_numpy(features_scalers[feature_name].transform(features_batch[feature_name])).float().to(device)\n",
    "            for feature_name in features_batch.keys()\n",
    "        }\n",
    "        targets_batch = {\n",
    "            target_name: torch.from_numpy(targets_scalers[target_name].transform(targets_batch[target_name])).float().to(device)\n",
    "            for target_name in targets_batch.keys()\n",
    "        }\n",
    "        \n",
    "        speed_and_delta_preds = one_actuator_model(**features_batch)['speed_and_delta']\n",
    "        speed_and_delta = targets_batch['speed_and_delta']\n",
    "        \n",
    "        loss = mse_loss(speed_and_delta_preds, speed_and_delta)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_total_mse += float(loss)\n",
    "        \n",
    "    avg_train_mse = train_total_mse / len(train_loader)  # TODO: this is not exactly true\n",
    "    print(f'Avg training MSE@{epoch}: {avg_train_mse:.3f}')\n",
    "    train_mses_for_plot.append(avg_train_mse)\n",
    "    \n",
    "        \n",
    "    ##############\n",
    "    # Validation #\n",
    "    ##############\n",
    "    valid_total_mse = 0\n",
    "    one_actuator_model.eval()\n",
    "    for features_batch, targets_batch in valid_loader:\n",
    "        features_batch = {\n",
    "            feature_name: torch.from_numpy(features_scalers[feature_name].transform(features_batch[feature_name])).float().to(device)\n",
    "            for feature_name in features_batch.keys()\n",
    "        }\n",
    "        targets_batch = {\n",
    "            target_name: torch.from_numpy(targets_scalers[target_name].transform(targets_batch[target_name])).float().to(device)\n",
    "            for target_name in targets_batch.keys()\n",
    "        }\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            speed_and_delta_preds = one_actuator_model(**features_batch)['speed_and_delta']\n",
    "        speed_and_delta = targets_batch['speed_and_delta']\n",
    "        \n",
    "        loss = mse_loss(speed_and_delta_preds, speed_and_delta)\n",
    "\n",
    "        valid_total_mse += float(loss)\n",
    "                \n",
    "    avg_valid_mse = valid_total_mse / len(valid_loader)\n",
    "    print(f'Avg validation MSE@{epoch}: {avg_valid_mse:.3f}\\n')\n",
    "    valid_mses_for_plot.append(avg_valid_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_mses_for_plot)\n",
    "plt.plot(valid_mses_for_plot);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_and_delta = speed_and_delta.cpu().numpy()\n",
    "speed_and_delta_preds = speed_and_delta_preds.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(speed_and_delta[:, 0], speed_and_delta_preds[:, 0])\n",
    "plt.gca().set_aspect('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(speed_and_delta[:, 1], speed_and_delta_preds[:, 1])\n",
    "plt.gca().set_aspect('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7bcfec8d1256c2cc01827278bf3ad7d8116bfe4d44c922aab01266a036f6cc2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('offline_rl': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
